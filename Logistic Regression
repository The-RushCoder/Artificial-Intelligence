import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import random

# Read dataset
data_frame = pd.read_csv("dataset.csv")
dataset_list = data_frame.values.tolist()

# Split dataset into train, validation, and test sets
Train_set = []
Val_set = []
Test_set = []
for data in dataset_list:
    x = random.uniform(0, 1)
    if 0 <= x <= 0.7:
        Train_set.append(data)
    elif 0.7 < x <= 0.85:
        Val_set.append(data)
    else:
        Test_set.append(data)

# Separate labels and features, insert bias term
store_train = [data[-1] for data in Train_set]
store_val = [data[-1] for data in Val_set]
store_test = [data[-1] for data in Test_set]

for data in Train_set:
    data.insert(0, 1)
for data in Val_set:
    data.insert(0, 1)
for data in Test_set:
    data.insert(0, 1)

# Sigmoid Function
def sigmoid(Z):
    return 1 / (1 + np.exp(-Z))

# Train logistic regression model
def train_model(Train_set, store_train, lr, max_iter):
    Theta = np.random.rand(len(Train_set[0]))
    Train_loss = []

    for _ in range(max_iter):
        TJ = 0
        for j in range(len(Train_set)):
            x = np.array(Train_set[j][:-1] + [1])
            y = store_train[j]
            Z = np.dot(Theta, x)
            h = sigmoid(Z)
            h = np.clip(h, 1e-15, 1 - 1e-15)
            J = (-y * np.log(h)) - ((1 - y) * np.log(1 - h))
            TJ += J
            dv = (h - y) * x
            Theta -= lr * dv
        TJ /= len(Train_set)
        Train_loss.append(TJ)

    return Train_loss, Theta

# Calculate validation accuracy for different learning rates
learning_rates = [0.1, 0.01, 0.001, 0.0001]
val_accs = []

for lr in learning_rates:
    Train_loss, Theta = train_model(Train_set, store_train, lr, max_iter=500)

    Correct = 0
    for i in range(len(Val_set)):
        x = np.array(Val_set[i][:-1] + [1])
        y = store_val[i]
        Z = np.dot(Theta, x)
        h = sigmoid(Z)
        if h >= 0.5:
            h = 1
        else:
            h = 0
        if h == y:
            Correct += 1

    val_acc = (Correct / len(Val_set)) * 100
    val_accs.append(val_acc)

# Create a table of learning rates and validation accuracies
table = pd.DataFrame({'Learning Rate': learning_rates, 'Validation Accuracy': val_accs})
print("Validation Accuracy for Different Learning Rates:")
print(table)

# Choose the learning rate with maximum validation accuracy
best_lr = learning_rates[np.argmax(val_accs)]

# Calculate test accuracy for the chosen learning rate
Train_loss, Theta = train_model(Train_set, store_train, best_lr, max_iter=500)

Correct = 0
for i in range(len(Test_set)):
    x = np.array(Test_set[i][:-1] + [1])
    y = store_test[i]
    Z = np.dot(Theta, x)
    h = sigmoid(Z)
    if h >= 0.5:
        h = 1
    else:
        h = 0
    if h == y:
        Correct += 1

test_accuracy = (Correct / len(Test_set)) * 100
print(f"\nThe Test accuracy for the chosen learning rate ({best_lr}) is: {test_accuracy} %")

# Plot train loss vs. epoch graph
plt.plot(range(0, 500), Train_loss)
plt.xlabel('Epoch')
plt.ylabel('Train Loss')
plt.title('Train Loss vs. Epoch')
plt.show()
